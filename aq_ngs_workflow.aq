{"config":{"title":"Duke NGS_Workflow","description":"This workflow aids in tracking and handling RNA_Seq for the Duke Genome Center","copyright":"UW_BIOFAB","version":"0.0.1","authors":[{"name":"Cannon","affiliation":"UW_BIOFAB"},{"name":"Amy Cash","affilation":"","affiliation":"UW_BIOFAB"}],"maintainer":{"name":"Cannon Mallory","email":"malloc3@uw.edu"},"acknowledgements":null,"github":{"user":"malloc3","repo":"aq_ngs_workflow"},"keywords":null,"aquadoc_version":"1.0.0","aquarium_version":"\u003c%= Bioturk::Application.config.aquarium_version %\u003e"},"components":[{"sample_types":[{"id":2,"name":"RNA Sample","description":"An individual unique sample of RNA","created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","field_types":[{"id":15,"parent_id":2,"name":"Customer","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":16,"parent_id":2,"name":"Code","ftype":"string","choices":null,"array":false,"required":true,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":17,"parent_id":2,"name":"Version","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":18,"parent_id":2,"name":"Type","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":19,"parent_id":2,"name":"Label","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":20,"parent_id":2,"name":"Organism","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":21,"parent_id":2,"name":"Conc","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":22,"parent_id":2,"name":"Volume","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":23,"parent_id":2,"name":"Pool","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]}]}],"object_types":[{"id":4,"name":"96 Well Sample Plate","description":"96 well sample plate","min":0,"max":1000,"handler":"collection","safety":"No safety information","cleanup":"No cleanup information","data":"No data","vendor":"No vendor information","created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T12:05:21.000-07:00","unit":"plate","cost":0.01,"release_method":"return","release_description":"","sample_type_id":null,"image":"","prefix":"","rows":8,"columns":12,"sample_type_name":null}],"operation_type":{"name":"Normalization Pooling","category":"RNA_Seq","deployed":false,"on_the_fly":false,"field_types":[{"ftype":"sample","role":"input","name":"Input Array","sample_types":["RNA Sample"],"object_types":["96 Well Sample Plate"],"part":false,"array":true,"routing":"IA","preferred_operation_type_id":null,"preferred_field_type_id":null,"choices":null},{"ftype":"sample","role":"output","name":"Output Array","sample_types":["RNA Sample"],"object_types":["96 Well Sample Plate"],"part":false,"array":true,"routing":"IA","preferred_operation_type_id":null,"preferred_field_type_id":null,"choices":null}],"protocol":"# Cannon Mallory\n# UW-BIOFAB\n# 03/04/2019\n# malloc3@uw.edu\n\nneeds 'Standard Libs/Debug'\nneeds 'Standard Libs/CommonInputOutputNames'\nneeds 'Standard Libs/Units'\nneeds 'Collection_Management/CollectionDisplay'\nneeds 'Collection_Management/CollectionTransfer'\nneeds 'Collection_Management/CollectionActions'\nneeds 'Collection_Management/CollectionLocation'\nneeds 'RNA_Seq/MiscMethods'\nneeds 'RNA_Seq/TakeMeasurements'\nneeds 'RNA_Seq/ParseCSV'\nneeds 'RNA_Seq/WorkflowValidation'\nneeds 'RNA_Seq/KeywordLib'\nneeds 'RNA_Seq/DataHelper'\nneeds 'RNA_Seq/CSVDebugLib'\n\n# Normalization Pooling\nclass Protocol\n  include Debug\n  include Units\n  include CollectionDisplay\n  include CollectionTransfer\n  include CollectionLocation\n  include CollectionActions\n  include CommonInputOutputNames\n  include WorkflowValidation\n  include DataHelper\n  include MiscMethods\n  include TakeMeasurements\n  include ParseCSV\n  include KeywordLib\n  include CSVDebugLib\n\n  TRANSFER_VOL = 20 # volume of sample to be transferred in ul\n\n  def main\n    return if validate_inputs(operations, inputs_match_outputs: true)\n    return if validate_qc(operations)\n\n    working_plate = setup_job(operations, TRANSFER_VOL, qc_step: false)\n\n    normalization_pooling(working_plate)\n    store_output_collections(operations, location: 'Freezer')\n  end\n\n  # Instructions for performing RNA_PREP\n  #\n  # @param working_plate [Collection] the plate with samples\n  def normalization_pooling(working_plate)\n    show do\n      title 'Do the Normalization Pooling Steps'\n      note \"Run Normalization Pooling protocol with plate #{working_plate.id}\"\n      table highlight_non_empty(working_plate, check: false)\n    end\n  end\nend\n","precondition":"#This precondition checks that all inputs into the operation have valid concentrations and are ready to be used.\n#Parts are copied from the WorkflowValidation Lib see note below for explination\n\ndef precondition(_op)\n  #pass = true\n  #_op = Operation.find(_op.id)\n  #_op.input_array(\"Input Array\").each do |field_value|\n  #  qc = field_value.item.get(\"cDNA QC\")\n  #  pass = false unless qc == \"Pass\"\n  #end\n  #_op.associate(\"Pass\".to_sym, pass)\n  #true if pass\n  true\nend","cost_model":"def cost(_op)\n  { labor: 0, materials: 0 }\nend","documentation":"#This protocol is for total Normalization Pooling of cDNA.  It Will take in a batch of samples, replate these\n#samples together onto a 96 well plate that will then go through a normalization steps.\n\nThis must be run after RNA QC, RNA Prep, and cDNA QC","test":"","timing":null}},{"sample_types":[{"id":2,"name":"RNA Sample","description":"An individual unique sample of RNA","created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","field_types":[{"id":15,"parent_id":2,"name":"Customer","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":16,"parent_id":2,"name":"Code","ftype":"string","choices":null,"array":false,"required":true,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":17,"parent_id":2,"name":"Version","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":18,"parent_id":2,"name":"Type","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":19,"parent_id":2,"name":"Label","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":20,"parent_id":2,"name":"Organism","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":21,"parent_id":2,"name":"Conc","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":22,"parent_id":2,"name":"Volume","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":23,"parent_id":2,"name":"Pool","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]}]}],"object_types":[{"id":5,"name":"Total RNA 96 Well Plate","description":"96 Well plate of total RNA from customer","min":0,"max":1000000,"handler":"collection","safety":"No safety information","cleanup":"No cleanup information","data":"No data","vendor":"No vendor information","created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-05-11T17:56:25.000-07:00","unit":"plate","cost":0.01,"release_method":"return","release_description":"","sample_type_id":2,"image":"","prefix":"ColdBoi","rows":8,"columns":12,"sample_type_name":"RNA Sample"},{"id":4,"name":"96 Well Sample Plate","description":"96 well sample plate","min":0,"max":1000,"handler":"collection","safety":"No safety information","cleanup":"No cleanup information","data":"No data","vendor":"No vendor information","created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T12:05:21.000-07:00","unit":"plate","cost":0.01,"release_method":"return","release_description":"","sample_type_id":null,"image":"","prefix":"","rows":8,"columns":12,"sample_type_name":null}],"operation_type":{"name":"RNA Prep","category":"RNA_Seq","deployed":false,"on_the_fly":false,"field_types":[{"ftype":"sample","role":"input","name":"Input Array","sample_types":["RNA Sample"],"object_types":["Total RNA 96 Well Plate"],"part":false,"array":true,"routing":"R","preferred_operation_type_id":null,"preferred_field_type_id":null,"choices":null},{"ftype":"sample","role":"output","name":"Output Array","sample_types":["RNA Sample"],"object_types":["96 Well Sample Plate"],"part":false,"array":true,"routing":"R","preferred_operation_type_id":null,"preferred_field_type_id":null,"choices":null}],"protocol":"# Cannon Mallory\n# UW-BIOFAB\n# 03/04/2019\n# malloc3@uw.edux\n\nneeds 'Standard Libs/Debug'\nneeds 'Standard Libs/CommonInputOutputNames'\nneeds 'Standard Libs/Units'\nneeds 'Standard Libs/UploadHelper'\nneeds 'Collection_Management/CollectionDisplay'\nneeds 'Collection_Management/CollectionTransfer'\nneeds 'Collection_Management/CollectionActions'\nneeds 'Collection_Management/CollectionLocation'\nneeds 'RNA_Seq/MiscMethods'\nneeds 'RNA_Seq/TakeMeasurements'\nneeds 'RNA_Seq/ParseCSV'\nneeds 'RNA_Seq/WorkflowValidation'\nneeds 'RNA_Seq/KeywordLib'\nneeds 'RNA_Seq/DataHelper'\nneeds 'RNA_Seq/CSVDebugLib'\n\nrequire 'csv'\n\nclass Protocol\n  include Debug\n  include Units\n  include CollectionDisplay\n  include CollectionTransfer\n  include CollectionLocation\n  include CommonInputOutputNames\n  include CollectionActions\n  include UploadHelper\n  include WorkflowValidation\n  include DataHelper\n  include MiscMethods\n  include TakeMeasurements\n  include ParseCSV\n  include KeywordLib\n  include CSVDebugLib\n\n  ADAPTER_TRANSFER_VOL = 12 # volume of adapter to transfer\n  TRANSFER_VOL = 20 # volume of sample to be transferred in ul\n  CONC_RANGE = (50...100).freeze # acceptable concentration range\n  CSV_HEADERS = ['Plate ID', 'Well Location'].freeze\n  CSV_LOCATION = 'Location TBD'.freeze\n  ADAPTER_KEY = 'Adapter_key'.to_sym\n\n  def main\n    return if validate_inputs(operations, inputs_match_outputs: true)\n    return if validate_qc(operations)\n\n    working_plate = setup_job(operations, TRANSFER_VOL, qc_step: false)\n\n    adapter_plates = make_adapter_plate(working_plate.parts.length)\n    adapter_plates.each do |adapter_plate|\n      working_plate.associate(ADAPTER_KEY, adapter_plate)\n      associate_plate_to_plate(to_collection: working_plate,\n                               from_collection: adapter_plate)\n    end\n\n    rna_prep_steps(working_plate)\n    store_output_collections(operations, location: 'Freezer')\n  end\n\n  # Instructions for performing RNA_PREP\n  #\n  # @param working_plate [Collection] the plate that has all samples in it\n  def rna_prep_steps(working_plate)\n    show do\n      title 'Run RNA-Prep'\n      note \"Run typical RNA-Prep Protocol with RNA plate #{working_plate.id}\n                and adapter plate #{working_plate.get(ADAPTER_KEY).class}\"\n      table highlight_non_empty(working_plate, check: false)\n    end\n  end\n\n  # Instructions for making an adapter plate\n  #\n  # @param num_adapter_needed [int] the number of adapters needed for job\n  # @return adapter_plate [Array\u003ccollection\u003e] plate with all required adapters\n  #\n  # TODO: Add feature so that they can specify the specific sample that the\n  #   adapter needs to match with Or perhapses specify the specific groups that\n  #   they need to go to (or a combination there of)\n  def make_adapter_plate(num_adapters_needed)\n    adapter_plates = []\n\n    show do\n      title 'Make Adapter Plate'\n      note 'On the next page upload CSV of desired Adapters'\n    end\n\n    up_csv = get_validated_uploads(min_length: num_adapters_needed, \n                                   headers: CSV_HEADERS, \n                                   file_location: CSV_LOCATION)\n    col_parts_hash = sample_from_csv(up_csv)\n\n    col_parts_hash.each do |collection_item, parts|\n      collection = Collection.find(collection_item.id)\n\n      plates = make_and_populate_collection(parts,\n                                            collection_type: COLLECTION_TYPE,\n                                            add_column_wise: true,\n                                            label_plates: false)\n      plates.each do |adapter_plate|\n        transfer_from_collection_to_collection(collection,\n                                             to_collection: adapter_plate,\n                                             transfer_vol: ADAPTER_TRANSFER_VOL,\n                                             populate_collection: false,\n                                             array_of_samples: parts)\n        adapter_plates.push(adapter_plate)\n      end\n    end\n    adapter_plates\n  end\n\n  # Parses CSV and returns an array of all the samples\n  #\n  #\n  # @param csv_uploads [array] array of uploaded CSV files\n  # @returns hash [key: collection, array[parts]] hash of collection and samples\n  def sample_from_csv(csv_uploads)\n    parts = []\n    csv = CSV.parse(csv_upload) if debug\n    csv_uploads.each do |upload|\n      csv = CSV.read(open(upload.url))\n\n      first_row = csv.first\n      first_row[0][0] = ''\n\n      id_idx = first_row.find_index(CSV_HEADERS[0])\n      loc_idx = first_row.find_index(CSV_HEADERS[1])\n      csv.drop(1).each do |row|\n        collection = Collection.find(row[id_idx])\n        part = part_alpha_num(collection, row[loc_idx])\n        parts.push(part)\n      end\n    end\n    parts.group_by(\u0026:containing_collection)\n  end\nend\n","precondition":"#This precondition checks that all inputs into the operation have valid concentrations and are ready to be used.\n#Parts are copied from the WorkflowValidation Lib see note below for explination\n\n#Dont want to return false.  Only return true if it passes\ndef precondition(op)\n  true \n  #_op = Operation.find(op.id)#\n\n  #loops = _op.get(\"Loops\".to_sym)\n  #_op.associate(\"Initial_Loopos\".to_sym, loops)\n  #if loops.nil?\n  #  loops = 0\n  #else\n  #  loops += 1\n  #end\n\n  #_op.associate(\"Loops\".to_sym, loops)\n\n#  pass = true\n#  range = (50...100)#\n\n  #_op.input_array(\"Input Array\").each do |field_value|\n  #  conc = field_value.part.get(\"Stock Conc (ng/ul)\".to_sym)\n  #  pass = false unless range.cover?(conc)\n  #end\n\n  ##if pass\n    #_op.associate(\"Pass is true\".to_sym, \"Pass was true\")\n    #_op.associate(\"Pass is false\".to_sym, \"Its actually true now\")\n    #_op.status = 'pending'\n    #_op.save\n  #end\nend","cost_model":"def cost(_op)\n  { labor: 0, materials: 0 }\nend","documentation":"This preps RNA and makes cDNA.  The actual steps of RNA Prep are not illustrated well (by direction from Duke Genome Center).\n\nPrimarily this Protocol assists in batching of jobs.   Must be run after RNA QC","test":"","timing":null}},{"sample_types":[{"id":2,"name":"RNA Sample","description":"An individual unique sample of RNA","created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","field_types":[{"id":15,"parent_id":2,"name":"Customer","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":16,"parent_id":2,"name":"Code","ftype":"string","choices":null,"array":false,"required":true,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":17,"parent_id":2,"name":"Version","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":18,"parent_id":2,"name":"Type","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":19,"parent_id":2,"name":"Label","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":20,"parent_id":2,"name":"Organism","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":21,"parent_id":2,"name":"Conc","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":22,"parent_id":2,"name":"Volume","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":23,"parent_id":2,"name":"Pool","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]}]}],"object_types":[{"id":5,"name":"Total RNA 96 Well Plate","description":"96 Well plate of total RNA from customer","min":0,"max":1000000,"handler":"collection","safety":"No safety information","cleanup":"No cleanup information","data":"No data","vendor":"No vendor information","created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-05-11T17:56:25.000-07:00","unit":"plate","cost":0.01,"release_method":"return","release_description":"","sample_type_id":2,"image":"","prefix":"ColdBoi","rows":8,"columns":12,"sample_type_name":"RNA Sample"}],"operation_type":{"name":"RNA QC","category":"RNA_Seq","deployed":false,"on_the_fly":false,"field_types":[{"ftype":"sample","role":"input","name":"Input Array","sample_types":["RNA Sample"],"object_types":["Total RNA 96 Well Plate"],"part":false,"array":true,"routing":"IS","preferred_operation_type_id":null,"preferred_field_type_id":null,"choices":null}],"protocol":"# Cannon Mallory\n# UW-BIOFAB\n# 03/04/2019\n# malloc3@uw.edu\n\nneeds 'Standard Libs/Debug'\nneeds 'Standard Libs/CommonInputOutputNames'\nneeds 'Standard Libs/Units'\nneeds 'Standard Libs/UploadHelper'\nneeds 'Standard Libs/ItemActions'\nneeds 'Collection_Management/CollectionDisplay'\nneeds 'Collection_Management/CollectionTransfer'\nneeds 'Collection_Management/CollectionActions'\nneeds 'Collection_Management/CollectionLocation'\nneeds 'RNA_Seq/MiscMethods'\nneeds 'RNA_Seq/TakeMeasurements'\nneeds 'RNA_Seq/ParseCSV'\nneeds 'RNA_Seq/WorkflowValidation'\nneeds 'RNA_Seq/KeywordLib'\nneeds 'RNA_Seq/DataHelper'\n\n# RNA QC\nclass Protocol\n  include CollectionActions\n  include CollectionDisplay\n  include CollectionTransfer\n  include CommonInputOutputNames\n  include Debug\n  include CollectionLocation\n  include Units\n  include UploadHelper\n  include WorkflowValidation\n  include DataHelper\n  include MiscMethods\n  include TakeMeasurements\n  include ParseCSV\n  include KeywordLib\n  include ItemActions\n\n  TRANSFER_VOL = 20 # volume of sample to be transferred in ul\n  PLATE_HEADERS = ['Plate',\t'Repeat',\t'End time',\n                   'Start temp.',\t'End temp.',\t'BarCode'].freeze\n  PLATE_LOCATION = 'TBD Location of file'.freeze\n\n  BIO_HEADERS = ['Well', 'Sample ID',\t'Conc. (ng/ul)',\n                 'RQN',\t'28S/18S'].freeze\n  BIO_LOCATION = 'TBD Location of file'.freeze\n\n  RIN_MIN = 3\n  RIN_MAX = 10\n\n  CONC_MIN = 8\n  CONC_MAX = 100\n  UP_MARG = 500\n  LOW_MARG = 5\n\n  def main\n    return true if validate_inputs(operations)\n\n    working_plate = setup_job(operations, TRANSFER_VOL, qc_step: true)\n\n    trash_object([working_plate])\n\n    setup_and_take_plate_reader_measurements(working_plate, PLATE_HEADERS,\n                                             PLATE_LOCATION)\n\n    setup_ad_take_bioanalizer_measurements(working_plate, BIO_HEADERS,\n                                           BIO_LOCATION, RIN_KEY, 0, 3)\n\n    rin_info = generate_data_range(key: RIN_KEY, minimum: RIN_MIN,\n                                   maximum: RIN_MAX)\n\n    conc_info = generate_data_range(key: CON_KEY, minimum: CONC_MIN,\n                                    maximum: CONC_MAX, lower_margin: LOW_MARG,\n                                    upper_margin: UP_MARG)\n\n    asses_qc_values(working_plate, [rin_info, conc_info])\n\n    show_key_associated_data(working_plate, [QC_STATUS, CON_KEY, RIN_KEY])\n\n    # TODO: For some reason it will not overwrite the old association...\n    associate_data_back_to_input(working_plate, [QC_STATUS, CON_KEY, RIN_KEY],\n                                 operations)\n\n    trash_object([working_plate])\n\n    downstream_op_type = 'RNA Prep'\n    return if stop_qc_failed_operations(operations, downstream_op_type)\n  end\nend\n","precondition":"def precondition(_op)\n  true\nend","cost_model":"def cost(_op)\n  { labor: 0, materials: 0 }\nend","documentation":"Total RNA QC\n\nPlates sub-samples onto a 96 well plate. Measures RNA concentration and associates it with the original samples.\n\nPrecursor to RNA_Prep","test":"","timing":null}},{"sample_types":[{"id":2,"name":"RNA Sample","description":"An individual unique sample of RNA","created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","field_types":[{"id":15,"parent_id":2,"name":"Customer","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":16,"parent_id":2,"name":"Code","ftype":"string","choices":null,"array":false,"required":true,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":17,"parent_id":2,"name":"Version","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":18,"parent_id":2,"name":"Type","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":19,"parent_id":2,"name":"Label","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":20,"parent_id":2,"name":"Organism","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":21,"parent_id":2,"name":"Conc","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":22,"parent_id":2,"name":"Volume","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]},{"id":23,"parent_id":2,"name":"Pool","ftype":"string","choices":null,"array":false,"required":false,"created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T11:53:31.000-07:00","parent_class":"SampleType","role":null,"part":null,"routing":null,"preferred_operation_type_id":null,"preferred_field_type_id":null,"allowable_field_types":[],"sample_types":[],"object_types":[]}]}],"object_types":[{"id":4,"name":"96 Well Sample Plate","description":"96 well sample plate","min":0,"max":1000,"handler":"collection","safety":"No safety information","cleanup":"No cleanup information","data":"No data","vendor":"No vendor information","created_at":"2020-04-10T11:53:31.000-07:00","updated_at":"2020-04-10T12:05:21.000-07:00","unit":"plate","cost":0.01,"release_method":"return","release_description":"","sample_type_id":null,"image":"","prefix":"","rows":8,"columns":12,"sample_type_name":null}],"operation_type":{"name":"cDNA QC","category":"RNA_Seq","deployed":false,"on_the_fly":false,"field_types":[{"ftype":"sample","role":"input","name":"Input Array","sample_types":["RNA Sample"],"object_types":["96 Well Sample Plate"],"part":false,"array":true,"routing":"IA","preferred_operation_type_id":null,"preferred_field_type_id":null,"choices":null}],"protocol":"# Cannon Mallory\n# UW-BIOFAB\n# 03/04/2019\n# malloc3@uw.edu\n#\n# This Protocol is to Quality check the C-DNA created.\n\nneeds 'Standard Libs/Debug'\nneeds 'Standard Libs/CommonInputOutputNames'\nneeds 'Standard Libs/Units'\nneeds 'Standard Libs/UploadHelper'\nneeds 'Collection_Management/CollectionDisplay'\nneeds 'Collection_Management/CollectionTransfer'\nneeds 'Collection_Management/CollectionActions'\nneeds 'Collection_Management/CollectionLocation'\nneeds 'RNA_Seq/MiscMethods'\nneeds 'RNA_Seq/TakeMeasurements'\nneeds 'RNA_Seq/ParseCSV'\nneeds 'RNA_Seq/WorkflowValidation'\nneeds 'RNA_Seq/KeywordLib'\nneeds 'RNA_Seq/DataHelper'\nneeds 'RNA_Seq/CSVDebugLib'\n\nclass Protocol\n  include CollectionDisplay\n  include CollectionTransfer\n  include CollectionActions\n  include CommonInputOutputNames\n  include Debug\n  include CollectionLocation\n  include WorkflowValidation\n  include DataHelper\n  include MiscMethods\n  include TakeMeasurements\n  include ParseCSV\n  include KeywordLib\n  include CSVDebugLib\n\n  TRANSFER_VOL = 20 # volume of sample to be transferred\n  PLATE_HEADERS = ['Plate',\t'Repeat',\t'End time',\t'Start temp.',\n                   'End temp.',\t'BarCode'].freeze\n  PLATE_LOCATION = 'TBD Location of file'.freeze\n\n  BIO_HEADERS = ['Well',\t'Sample ID',\t'Range',\t'ng/uL',\t'% Total',\n                 'nmole/L',\t'Avg. Size',\t'%CV'].freeze\n  BIO_LOCATION = 'TBD Location of file'.freeze\n\n  SIZE_MIN = 3\n  SIZE_MAX = 10\n\n  CONC_MIN = 8\n  CONC_MAX = 100\n  UP_MARG = 500\n  LOW_MARG = 5\n\n  def main\n    return true if validate_inputs(operations)\n\n    working_plate = setup_job(operations, TRANSFER_VOL, qc_step: true)\n\n    setup_and_take_plate_reader_measurements(working_plate, PLATE_HEADERS, \n                                             PLATE_LOCATION)\n    setup_ad_take_bioanalizer_measurements(working_plate, BIO_HEADERS, BIO_LOCATION,\n                                           AVE_SIZE_KEY, 0, 6)\n\n    ave_size_info = generate_data_range(key: AVE_SIZE_KEY, minimum: SIZE_MIN,\n                                        maximum: SIZE_MAX)\n\n    conc_info = generate_data_range(key: CON_KEY, minimum: CONC_MIN,\n                                    maximum: CONC_MAX, lower_margin: LOW_MARG,\n                                    upper_margin: UP_MARG)\n\n    asses_qc_values(working_plate, [ave_size_info, conc_info])\n\n    show_key_associated_data(working_plate, [QC_STATUS, CON_KEY, AVE_SIZE_KEY])\n\n    # TODO: For some reason it will not overwrite the old association...\n    associate_data_back_to_input(working_plate, [QC_STATUS, CON_KEY, RIN_KEY],\n                                 operations)\n\n    trash_object(working_plate)\n\n    downstream_op_type = 'RNA Prep'\n    return if stop_qc_failed_operations(operations, downstream_op_type)\n  end\nend\n","precondition":"def precondition(_op)\n  true\nend","cost_model":"def cost(_op)\n  { labor: 0, materials: 0 }\nend","documentation":"#This Protocol is to Quality check the cDNA created in RNA Prep.  Must be run after RNA Prep but before Normalization Pooling","test":"","timing":null}},{"library":{"name":"CsvDebugLib","category":"RNA_Seq","code_source":"module CsvDebugLib\n    CSV_DEBUG = \"Plate ID, Well Location\n1598,A1\n1598,A2\n1598,A3\n1598,A4\n1597,C1\n1597,C2\n1597,C3\n1597,C4\n1597,C5\n1597,C6\n1597,C7\n1597,C8\"\n\n    CSV_CONC = \"Plate Position, Well Position, Conc (ng/ul)\n    A01,A1,58\n    B01,B1,55\n    C01,C1,60\n    D01,D1,67\n    E01,E1,66\n    F01,F1,88\n    G01,G1,98\n    A02,A2,74\n    B02,B2,92\n    C02,C2,57\n    D02,D2,58\n    E02,E2,99\n    F02,F2,56\n    G02,G2,58\n    A03,A3,66\n    B03,B3,57\n    C03,C3,66\n    D03,D3,99\n    E03,E3,87\n    F03,F3,78\n    G03,G3,56\"\nend"}},{"library":{"name":"DataHelper","category":"RNA_Seq","code_source":"\n\nneeds 'Standard Libs/CommonInputOutputNames'\nneeds 'Standard Libs/AssociationManagement'\nneeds 'Standard Libs/Units'\nneeds 'Standard Libs/UploadHelper'\nneeds 'RNA_Seq/KeywordLib'\n    \nmodule DataHelper    \n  include CommonInputOutputNames\n  include Units\n  include UploadHelper\n  include AssociationManagement\n  include KeywordLib\n\n\n  # Gets the standards used and information about them from tech\n  #\n  # @param tries [Int] optional the number of tries the tech gets\n  #   to input standard information\n  # @return []  the standards used in plate reader measurement\n  def get_standards(tries: 10)\n    fluorescence = []\n    standard = []\n\n    tries.times do |laps|\n      # TODO make this a table and not just a bunch of inputs\n      response = show do\n        title \"Plate Reader Standards\"\n        note 'Please record the standards used and their fluorescence below'\n        get \"number\", var: \"stan_1\", label: \"Concentration 1 (ng/ul)\", default: \"\"\n        get \"number\", var: \"flo_1\", label: \"Fluorescence 1\", default: \"\"\n        separator\n        get \"number\", var: \"stan_2\", label: \"Concentrationn 2 (ng/ul)\", default: \"\"\n        get \"number\", var: \"flo_2\", label: \"Fluorescence 2\", default: \"\"\n      end\n      # This is because in this case  the lower concentration should always be first\n      # else slope will be negative.   Rather do it here than in the slope calculation\n      # because the slope calulation may be used other places and thus needs to be able\n      # to report a neg slope.\n      if response[:stan_1] \u003e response[:stan_2]\n        point_two = [response[:flo_1], response[:stan_1]]\n        point_one = [response[:flo_2], response[:stan_2]]\n      else\n        point_one = [response[:flo_1], response[:stan_1]]\n        point_two = [response[:flo_2], response[:stan_2]]\n      end\n      \n      return [point_one, point_two] unless point_two.include?(\"\") || point_one.include?(\"\")\n\n      raise \"Too many attempts to input Plate Reader Standards information\" if laps \u003e tries - 1\n      show do \n        title \"Plate Reader Standards not Entered Properly\"\n        warning \"Please input valid Standard Values\"\n        note \"Hit okay to try again\" \n      end\n    end\n  end\n\n\n\n\n  # Calculates the slope and intercept between two points\n  #\n  # @param point_one [Array\u003cx,y\u003e] the x,y coordinates of point one\n  # @param point_two [Array\u003cx,y\u003e] the x,y coordinates of point two \n  def calculate_slope_intercept(point_one: standards[0], point_two: standards[1])\n    x_1 = point_one[0]\n    y_1 = point_one[1]\n    x_2 = point_two[0]\n    y_2 = point_two[1]\n    \n    slope = (y_2 - y_1).to_f/(x_2 - x_1)\n    intercept = y_1 - (slope * x_1)\n    [slope, intercept]\n  end\n\n\n\n  # calculates the concentrations of the samples from the slope, intercept, dilution factor\n  # and the plate reader information.\n  #\n  # @param slope [Float] the slope of the calibration curve\n  # @param intercept [Float] the intercept of the calibration curve\n  # @param plate_csv [CSV] csv file partially parsed with plate reader values\n  # @param dilution_map [Array\u003cArray\u003cr,c, dilution factor\u003e\u003e] the dilution factor map\n  # @param concentration_map [Array\u003cArray\u003cr,c, concentration\u003e\u003e] map of concentrations\n  def calculate_concentrations(slope:, intercept:, plate_csv:, dilution_map:)\n    concentration_map = []\n    dilution_map.each do |row, column, dilution|\n      fluorescence = plate_csv[row][column].to_f\n      concentration = ((fluorescence * slope + intercept)*dilution/1000).round(1)\n      concentration_map.push([row,column,concentration])\n    end\n    concentration_map\n  end\n\n\n\n\n  # Generates a hash with the margin range and the data key.  To be passed to \n  # \"asses_qc_values\" method \n  def generate_data_range(key:, minimum:, maximum:, lower_margin: nil, upper_margin: nil)\n    good_range = (minimum...maximum+1)\n    margin = []\n\n    #couldn't use unless since I needed if later\n    if !lower_margin.nil? || !upper_margin.nil?\n      margin = (lower_margin...upper_margin)\n    elsif lower_margin.nil?\n      margin = (minimum... upper_margin)\n    else upper_margin.nil?\n      margin = (lower_margin...maximum)\n    end\n\n    {'key': key, 'pass': good_range, 'margin': margin}\n  end\n\n\n\n\n  # Asses weather the data held in info array keys are within the \n  # margins given by the hash\n  #\n  # @param collection [Collection] the collection in question\n  # @param info_array [Array\u003cHash{key, pass, margin}]\n  def asses_qc_values(collection, info_array)\n    data_map = []\n    collection.parts.each do |part|\n        overall_status = nil\n        info_array.each do |info_hash|\n          key = info_hash[:key]\n          pass_array = info_hash[:pass]\n\n          margin = info_hash[:margin]\n\n          #data = get_associated_data(part, key).to_f\n          data = part.get(key).to_f\n\n          if pass_array.include?(data)\n            point_status = 'pass'\n          elsif margin.include?(data)\n            point_status = 'margin'\n          elsif data.nil?\n            point_status = nil\n          else\n            point_status = 'fail'\n          end\n\n          change_arry = ['margin', 'fail']\n          unless point_status == overall_status\n            if overall_status.nil?\n              overall_status = point_status\n            elsif overall_status == 'pass' \u0026\u0026 change_arry.include?(point_status)\n              overall_status = point_status\n            end\n          end\n\n        end\n        unless overall_status.nil?\n          location = collection.find(part)\n          location.push(overall_status)\n          location.push(QC_STATUS)\n          data_map.push(location)\n        end\n    end \n    associate_value_key_to_parts(plate: collection, data_map: data_map)\n  end\n\n\n\n\n  # Associates data back to the input samples based on the source determined from \n  # provenance.\n  #\n  # @param collection [Collection] the collection with items of question\n  # @param array_of_keys [Array\u003cstring\u003e] an array or keys for the associations\n  #       that need to be back associated\n  def associate_data_back_to_input(collection, array_of_keys, operations)\n    input_io_fv = get_input_field_values(operations)\n    collection.parts.each do |part|\n      sources = part.get('source')\n      sources.uniq! #so if multiple sources are the same item data\n      # is transferred only once\n      sources.each do |sample_source|\n        unless sample_source.nil?\n          field_value = input_io_fv.select{|io_fv| io_fv.part.id == sample_source[:id]}.first\n          array_of_keys.each do |key|\n            data_obj = part.get(key)\n            field_value.associate(key, data_obj) unless data_obj.nil?\n          end\n        end\n      end\n    end\n  end\n\n  # Generates a standard dilution factor map.  Assumes that there was no dilution.\n  #\n  # @param working_plate [Collection] the collection that the map is being generated for\n  # @return dilution_factor_map [Array\u003cr,c,dilution_factor\u003e] map of dilutions\n  def generate_100_dilution_factor_map(working_plate)\n    parts = working_plate.parts\n    dilution_factor_map = []\n    parts.each do |part|\n      loc = working_plate.find(part).first\n      loc.push(100)\n      dilution_factor_map.push(loc)\n    end\n    dilution_factor_map\n  end\n\nend"}},{"library":{"name":"KeywordLib","category":"RNA_Seq","code_source":"# frozen_string_literal: true\n\n# Cannon Mallory\n# malloc3@uw.edu\n#\n# This is where all the standard keywords/values will live.\n\nmodule KeywordLib\n  MAX_INPUTS = 96\n  COLLECTION_TYPE = '96 Well Sample Plate'\n  CON_KEY = 'Stock Conc (ng/ul)'\n  QC2_KEY = 'cDNA QC'\n  DILUTION_FACTOR = 'Dilution Factor'\n\n  ADAPTER_PLATE = 'Adapter Plate'\n  ADAPTER = 'Adapter Item'\n\n  INPUT_PLATE = 'Input Plate'\n  INPUT_ITEM = 'Input Item'\n\n  PLATE_READER_DATA_KEY = \"Plate Reader Data\"\n  BIOANALYZER_KEY = \"Bioanalyzer Data\"\n  RIN_KEY = \"Rin Number\"\n\n  AVE_SIZE_KEY = \"Avg. Size\"\n\n  QC_STATUS = \"QC Status\"\n\nend\n"}},{"library":{"name":"MiscMethods","category":"RNA_Seq","code_source":"# A library for all the parts of this workflow that are repeated between\n# multiple operations however do not neatly fit in any other library\n\nneeds 'Standard Libs/CommonInputOutputNames'\nneeds 'Collection_Management/CollectionDisplay'\nneeds 'Collection_Management/CollectionTransfer'\nneeds 'Collection_Management/CollectionActions'\nneeds 'RNA_Seq/KeywordLib'\n    \n    \n    \nmodule MiscMethods\n  include CollectionActions\n  include CollectionDisplay\n  include CollectionTransfer\n  include KeywordLib\n  include CommonInputOutputNames\n\n  \n  # Sets up the job and manages transfers etc all that jazz\n  #\n  # @param operations [OperationList] list of operations\n  # @param transfer_vol [Int or Float] the volume that is to be transferred\n  def setup_job(operations, transfer_vol, qc_step: false)\n    operations.retrieve\n    working_plate = transfer_steps(operations, transfer_vol, qc_step: qc_step)\n\n    if false #qc_step\n      #this is so if the protocol fails we don't end up with a bunch of \n      # plates in inventory that actually don't exist. \n      working_plate.mark_as_deleted\n      working_plate.save\n    end\n\n    store_inputs(operations)\n    working_plate\n  end\n\n  \n    \n  # Handles the transfers for the two qc steps\n  #\n  # @param operations [OperationList] list of operations\n  # @param working_plate [collection] the plate being transferred to\n  # @transfer_vol [Int or Float] the volume being transferred\n  def transfer_steps(operations, transfer_vol, qc_step: false)\n    input_field_value_array = []\n    output_fv_array = []\n    operations.each do |op|\n      input_field_value_array += op.input_array(INPUT_ARRAY)\n      output_fv_array += op.output_array(OUTPUT_ARRAY) unless qc_step\n    end\n\n    plates = transfer_subsamples_to_working_plate(input_field_value_array, collection_type: COLLECTION_TYPE, \n                                                                    transfer_vol: transfer_vol,\n                                                                    add_column_wise: true)\n\n    associate_field_values_to_plate(output_fv_array, plates) unless qc_step\n\n    if plates.length \u003e 1\n      raise 'Too many items'\n    end\n    plates.first\n  end\n\n\n    # Gets all input field values from all input operations\n  #\n  # @param operations [OperationList] list of operations\n  # @return [Array\u003cio_field_values\u003e]\n  def get_input_field_values(operations)\n    io_field_values  = []\n    operations.each do |op|\n      io_field_values += op.input_array(INPUT_ARRAY)\n    end\n    io_field_values\n  end\n\n\n  # Shows key associated data in the collection based on\n  # the array of keys in the data keys list\n  #\n  # @param collection [Collection] the collection\n  # @param data_keys [Array\u003cKeys\u003e] keys can be string or\n  #     anything that data associator can use\n  def show_key_associated_data(collection, data_keys)\n    show do\n      title \"Measured Data\"\n      note \"Listed below are the data collected\"\n      note \"(Concentration (ng/ul), RIN Number)\"\n      table display_data(collection, data_keys)\n      #  TODO add in feature for tech to change QC Status\n    end\n  end\n    \nend"}},{"library":{"name":"ParseCSV","category":"RNA_Seq","code_source":"needs 'Collection_Management/CollectionLocation'\nneeds 'RNA_Seq/KeywordLib'\n\nmodule ParseCSV\n  include CollectionLocation\n  include KeywordLib\n    \n  # Parses a csv for data assuming headers fit certain format\n  #  Header 1    Header 2    Header 3\n  #    loc         data      data\n  #    loc         data       data\n  # \n  # @param csv [CSV] the csv file\n  # @param data_header [String] the string name of the header containing the information of interest\n  # @param alpha_num_header [String] optional the name of the header containing the \n  #               alpha numerical well location\n  def parse_csv_for_data(csv, data_header:, alpha_num_header:)\n    data_idx = csv.first.index(data_header)\n    loc_idx = csv.first.index(alpha_num_header)\n    data_map = []\n    csv.drop(1).each do |row|\n      alpha_loc = row[loc_idx]\n      data = row[data_idx]\n      rc_loc = convert_location_to_coordinates(alpha_loc)\n      data_map.push(rc_loc.push(data))\n    end\n    data_map\n  end\n  \n  \n  \n    # Does initial formatting and parseing of csv files\n  #\n  # @param csv_uploads [Upload] raw uploaded csv files\n  # @return [Array\u003ccsv, Hash\u003e] retunrs an array containg the semi parse csv\n  #    and a hash of general plate reader run info.\n  def pre_parse_plate_reader_data(csv_uploads)\n    upload = csv_uploads.first\n    csv = CSV.read(open(upload.url))\n    plate_reader_info = {\n      'repeats' =\u003e csv[1][1],\n      'end_time' =\u003e csv[1][2],\n      'start_temp'  =\u003e csv[1][3],\n      'end_temp' =\u003e csv[1][4],\n      'bar_code' =\u003e csv[1][5]\n      }\n    [csv, plate_reader_info]\n  end\n  \n  \nend"}},{"library":{"name":"TakeMeasurements","category":"RNA_Seq","code_source":"needs 'Standard Libs/AssociationManagement'\nneeds 'Collection_Management/CollectionData'\nneeds 'RNA_Seq/ParseCSV'\nneeds 'RNA_Seq/WorkflowValidation'\nneeds 'RNA_Seq/DataHelper'\nneeds 'RNA_Seq/KeywordLib'\n    \n    \n    \nmodule TakeMeasurements\n  include CollectionData\n  include AssociationManagement\n  include DataHelper\n  include ParseCSV\n  include KeywordLib\n\n  # Sets up and take Bioanalyzer measurements and associates the information back to \n  # the items in the working plate\n  #\n  # @param working_plate [Collection] the working plate\n  # @param bio_headers, [Array\u003cString\u003e] the headers that should be in the excel sheet\n  # @param bio_location [String] the location of the file that comes from the plate reader\n  # @param data_key [String] the key that teh data should be associated to\n  # @param loc_col [Int] the column in the csv that the well location is listed\n  # @param data_col [Int] the column in the csv that the data is located in\n  def setup_ad_take_bioanalizer_measurements(working_plate, bio_headers, bio_location, \n    data_key, loc_col, data_col)\n    if data_key = RIN_KEY\n      measurement_type = 'rna'\n    elsif data_key = AVE_SIZE_KEY\n      measurement_type = 'library'\n    else\n      measurement_type = data_key\n    end\n\n    bio_csv = take_bioanalizer_measurement(working_plate, bio_headers, bio_location,\n          measurement_type: measurement_type)\n\n    data_map = parse_csv_for_data(bio_csv, data_header: bio_headers[data_col], alpha_num_header: bio_headers[loc_col])\n    associate_value_to_parts(plate: working_plate, data_map: data_map, key: data_key)\n  end\n    \n  # Sets up and take plate reader measurements and associates the information back to \n  # the items in the working plate\n  #\n  # @param working_plate [Collection] the working plate\n  # @param plate_headers, [Array\u003cString\u003e] the headers that should be in the excel sheet\n  # @param plate_location [String] the location of the file that comes from the plate reader    \n  def setup_and_take_plate_reader_measurements(working_plate, plate_headers, plate_location)\n    dilution_factor_map = get_dilution_factors(working_plate)\n    associate_value_to_parts(plate: working_plate, data_map: dilution_factor_map, key: DILUTION_FACTOR)\n\n    plate_reader_csv, standards = take_duke_plate_reader_measurement(working_plate, plate_headers, plate_location)\n    slope, intercept = calculate_slope_intercept(point_one: standards[0], point_two: standards[1])\n\n    concentration_map = calculate_concentrations(slope: slope, intercept: intercept, \n                plate_csv: plate_reader_csv, dilution_map: dilution_factor_map)\n    associate_value_to_parts(plate: working_plate, data_map: concentration_map, key: CON_KEY)\n  end\n\n  # TODO\n  # Gets the dilution factors used in the plate reader measurements\n  # Need some guidance on how this is determined.  I expect that this is something\n  # that can automatically be generated within aquarium.  But also may require\n  # some user input?   For now leave it open for change\n  #\n  # @return dilution_factor_map [Array\u003cr,c,x\u003e] a map of dilution factors and location\n  def get_dilution_factors(working_plate)\n    show do \n      title \"Dilution Factor\"\n      note \"Need to determine how this is decided.  For now dilution is assumed to be\n        100.\"\n      note \"A user input may be needed or further understanding and control of,\n              the transfer step may be required...\"\n    end\n    generate_100_dilution_factor_map(working_plate)\n  end\n\n\n  # Instructions for taking the QC Plate Reader measurements\n  # \n  #\n  # @param working_plate [Collection] the plate of samples needing measurements\n  # @return parsable csv file map of fluorescence values\n  def take_duke_plate_reader_measurement(working_plate, csv_headers, csv_location)\n    standards = get_standards\n\n    show do\n      title \"Load Plate #{working_plate.id} on Plate Reader\"\n      note 'Load plate on plate reader and take measurements'\n      note 'Save output data as CSV and upload on next page'\n    end\n\n    detailed_instructions = \"Upload Plate Reader measurement files\"\n    csv_uploads = get_validated_uploads(working_plate.parts.length,\n      csv_headers, false, file_location: csv_location, detailed_instructions: detailed_instructions)\n\n    csv, plate_reader_info = pre_parse_plate_reader_data(csv_uploads)\n\n    associate_data(working_plate, PLATE_READER_DATA_KEY, plate_reader_info)\n    [csv.drop(6), standards]\n  end\n\n\n  # Instructions for taking Duke Bioanalyzer measurements \n  # \n  #\n  # @param working_plate [Collection] the plate of samples needing measurements\n  # @return parsable csv file map of fluorescence values\n  def take_bioanalizer_measurement(working_plate, csv_headers, csv_location, measurement_type: nil)\n    if measurement_type == 'library'\n      description = 'Library DNA'\n    elsif measurement_type == 'rna'\n      description = 'RNA'\n    else\n      description = measurement_type\n    end\n    \n    show do\n      title \"Load Plate #{working_plate.id} onto the Bioanalyzer\"\n      note \"Load plate onto the Bioanalyzer and take \u003cb\u003e#{description}\u003c/b\u003e measurements\"\n      note 'Save output data as CSV and upload on next page'\n    end\n\n    detailed_instructions = \"Upload Bioanalyzer #{description} measurement files\"\n    csv_uploads = get_validated_uploads(working_plate.parts.length,\n      csv_headers, false, file_location: csv_location, detailed_instructions: detailed_instructions)\n\n    upload = csv_uploads.first\n    csv = CSV.read(open(upload.url))\n\n    associate_data(working_plate, BIOANALYZER_KEY, csv)\n    csv\n  end\nend"}},{"library":{"name":"WorkflowValidation","category":"RNA_Seq","code_source":"# frozen_string_literal: true\n\n# Cannon Mallory\n# malloc3@uw.edu\n#\n# Module that validates workflow parameters at run time\nneeds 'Standard Libs/AssociationManagement'\nneeds 'Standard Libs/CommonInputOutputNames'\nneeds 'RNA_Seq/KeywordLib'\n\nmodule WorkflowValidation\n  include AssociationManagement\n  include CommonInputOutputNames\n  include KeywordLib\n\n  # Validates that total inputs (from all operations)\n  # are within the acceptable range\n  # \n  # @param operations [OperationList] list of all operations in the job\n  # @param inputs_match_outputs [Boolean] check if number of inputs matches number of outputs\n  # @return cancel_job [Boolean] true if job should be canceled/ended now\n  def validate_inputs(operations, inputs_match_outputs: false)\n    total_inputs = []\n    total_outputs = []\n    operations.each do |op|\n      total_inputs += op.input_array(INPUT_ARRAY).map! { |fv| fv.sample }\n      total_outputs += op.output_array(OUTPUT_ARRAY).map! { |fv| fv.sample }\n    end\n\n\n    a = total_inputs.detect{ |item| total_inputs.count(item) \u003e 1}\n    message = ''\n    message += \"Item #{a.id} has been included multiple times in this job,\" if a != nil\n    message += 'The number of Input Items and Output\n            Items do not match,' if total_inputs.length != total_outputs.length \u0026\u0026 inputs_match_outputs\n    message += 'Too many Items for this job. Please re-launch \n            job with fewer Items,' if total_inputs.length \u003e MAX_INPUTS\n    message += 'There are no Items for this job.' if total_inputs.length \u003c= 0\n    return end_job(operations, message: message) unless message == ''\n    false\n  end\n\n  # Displays all erred operations and items that failed QC\n  # Walks through all validation fails.\n  #\n  # @param failed_ops [Hash] Key: Operation ID, Value: Array[Items]\n  def show_erred_operations(failed_ops)\n    show do \n      title \"Some Operations have failed QC\"\n      note \"\u003cb\u003e#{failed_ops.length}\u003c/b\u003e Operations have Items that failed QC\"\n      note \"The next few pages will show which Operations and Items\n              are at fault\"\n    end\n\n    failed_ops.each do |op, erred_items|\n      show do\n        title \"Failed Operation and Items\"\n        note \"Operation \u003cb\u003e#{op.id}\u003c/b\u003e from Plan \u003cb\u003e#{op.plan.id}\u003c/b\u003e\"\n        erred_items.each do |item|\n          note \"Item \u003cb\u003e#{item.id}\u003c/b\u003e\"\n        end\n      end\n    end\n  end\n\n  \n  # Validates that operations have passed QC\n  #\n  # @param operations [OperationList] list of operations\n  def validate_qc(operations)\n    failed_ops = get_qc_fails(operations)\n    manage_failed_ops(operations, failed_ops)\n  end\n\n\n\n\n  # Get all the operation that did not pass QC\n  #\n  # @param operations [OperationList] list of all operations\n  # @return failed_ops [OperationList] list of all failed operations\n  def get_qc_fails(operations)\n    failed_ops = Hash.new\n    operations.each do |op|\n      failed_items = []\n      op.input_array(INPUT_ARRAY).each do |fv|\n        if get_associated_data(fv, QC_STATUS) == 'fail'\n          failed_items.push(fv)\n        end\n      end\n      failed_ops[op] = failed_items\n    end\n    failed_ops\n  end\n\n\n\n\n  # Manages failed ops.  Coordinates what needs to happen with failed operations\n  # Can return remove all items from the operation list Operations\n  # this is useful for certain fail criteria but must be careful else\n  # things will act very oddly\n  #\n  # @param operations [OperationList] lis of operations\n  # @param failed_ops [Hash] list of failed operations (OperationList okay too)\n  # @param interactive [Boolean] if true then is interactive.  Else will automatically\n  #     fail failed ops but continue good ops\n  # @return cancel_job [Boolean] true if job should be canceled\n  def manage_failed_ops(operations, failed_ops, interactive: true, \n      error_failed: false, delay_similar_ops: true)\n    unless failed_ops.empty?\n      this_job = operations.first.jobs.last\n\n      #must remove all ops from the job that are in the same plan as the failed ops\n      removed_ops = get_removed_ops(operations, failed_ops)\n\n      #get the total number of items that were removed from the job\n      num_items_removed = get_num_items(failed_ops)\n      num_items_removed += get_num_items(removed_ops) if delay_similar_ops \n\n      #get total number of items originally in th job\n      total_items = get_num_items(operations)\n\n      #get the number of items still in the job\n      num_items_left = total_items - num_items_removed\n\n      cancel_ops_and_pause_plans(operations, failed_ops, additional_ops: removed_ops, \n        error_failed: error_failed, delay_similar_ops: delay_similar_ops)\n      \n      cancel_job = false\n      if operations.empty?\n        cancel_job = true\n      elsif interactive\n        cancel_job = get_cancel_feedback(total_items, num_items_removed, num_items_left)\n        show_erred_operations(failed_ops)\n      end\n\n      return end_job(operations) if cancel_job\n      false\n    end\n  end\n\n\n  \n  # cancels the job.  Sets all operations passed to pending\n  # and returns true.   Assumes that in protocol code there\n  # exists a case statement if true will skip the rest of \n  # protocol and end protocol (without error)\n  #\n  # Will also display a message (that can be customized) about\n  # canceling the job\n  #\n  # operations [Array\u003cOperation\u003e] an array (or OperationList)of ops\n  # message [String] optional sting for canceled message\n  def end_job(operations, message: nil)\n    set_to_pending(operations)\n    show do\n      title \"Job Ended\"\n      unless message.nil?\n        note \"#{message}\"\n      else\n        note \"This job has been ended\"\n      end\n    end\n    true\n  end\n\n\n\n\n  # sets the operations in the list given to pending\n  #\n  # operations [Array\u003cOperation\u003e] an array (or OperationList)of ops\n  def set_to_pending(operations)\n    operations.each do |op|\n      op.set_status_recursively('pending')\n    end\n  end\n\n\n  # gets feed back from the tech on weather they want to continue with\n  # the job or to cancel and re batch.\n  #\n  # @param total_items [Int] the total number of items in the job\n  # @param num_failed [Int] number of failed items\n  # @param num_left [Int] number of items left in job\n  # @return cancel [Boolean] true if the job should be canceled\n  def get_cancel_feedback(total_items, num_failed, num_left, num_tries: 10)\n    cancel = nil\n    num_tries.times do \n      feedback_one = show do \n        title \"Some Items in this Job failed QC\"\n        separator\n        warning \"Warning\"\n        separator\n        note \"\u003cb\u003e#{num_failed}\u003c/b\u003e out of \u003cb\u003e#{total_items}\u003c/b\u003e items were \n              removed from this job\"\n        note \"Do you want to continue this job with the remaining \u003cb\u003e#{num_left}\u003c/b\u003e items\"\n        select [\"Yes\", \"No\"], var: \"continue\".to_sym, label: \"Continue?\", default: 1\n      end\n\n      if feedback_one[:continue] == \"No\"\n        feedback_two = show do\n          title \"Are You Sure?\"\n          note \"Are you sure you want to cancel the whole job?\"\n          select [\"Yes\", \"No\"], var: \"cancel\".to_sym, label: \"Cancel?\", default: 1\n        end\n        if feedback_two[:cancel] == \"Yes\"\n          return true\n        end\n      else\n        return false\n      end\n    end\n    raise \"Job Canceled, answer was not consistent.  All Operations erred\"\n  end\n\n  # get all the operations that may be in the same plan that should be removed\n  # from the job but should not be canceled or erred.\n  #\n  # @param operations [OperationList] list of operations\n  # @param failed_ops [Hash] hash of key op: value Array[Items]\n  # @return removed_ops [Array] list of operations that should be removed\n  def get_removed_ops(operations, failed_ops)\n    removed_ops = []\n    failed_ops.each do |failed_op, erred_items|\n      plan = failed_op.plan\n      operations.each do |op|\n        unless failed_ops.keys.include?(op) || removed_ops.include?(op) || op.plan != plan\n          removed_ops.push(op)\n        end\n      end\n    end\n    removed_ops\n  end\n\n\n\n  # cancels all failed ops and removes from operations list\n  # sets all like ops in same plans as failed ops to 'delayed'\n  # Can return remove all items from the operationlist Operations\n  # this is useful for certain fail criteria but must be careful else\n  # things will act very oddly\n  #\n  # @param operations [OperationList] list of operations\n  # @param failed_ops [Hash] list of failed operations\n  # @param removed_ops [Array] list of ops that did not fail but need to be removed from plan\n  def cancel_ops_and_pause_plans(operations, failed_ops, additional_ops: nil, \n            error_failed: false, delay_similar_ops: true)\n    cancel_ops(operations, failed_ops, error_op: error_failed)\n    cancel_ops(operations, additional_ops) if delay_similar_ops \u0026\u0026 !additional_ops.nil?\n    pause_like_ops(failed_ops) if delay_similar_ops\n  end\n\n\n  # 'delay' all like ops in plans that contained failed_ops\n  #\n  # @param operations [OperationList] list of operations\n  # @param failed_ops [Hash] list of failed operations\n  def pause_like_ops(failed_ops)\n    failed_ops.keys.each do |failed_op|\n      plan = failed_op.plan\n      pause_ops_of_type(plan, failed_op.operation_type.name)\n    end\n  end\n\n  # moves all operations in a plan of a certain object type to delayed\n  # @param plan [Plan] the plan\n  # @param operation_type [String] the name of the operation type\n  # @param exclude [Array\u003coperation\u003e] an array of operations to \n  #    be excluded\n  def pause_ops_of_type(plan, operation_type, exclude: [])\n    ops = plan.operations.select{|op| op.operation_type.name == operation_type}\n    ops.each do |op|\n      op.set_status_recursively('delayed') unless exclude.include?(op)\n    end\n  end\n\n  # cancels all failed ops and removes them from operations list\n  #\n  # @param remove_ops [Array] or [Hash] list of failed operations\n  def cancel_ops(operations, remove_ops, error_op: false)\n\n    if remove_ops.is_a?(Hash)\n      remove_ops = remove_ops.keys\n    end\n\n    remove_ops.each do |op|\n      if error_op\n        op.set_status_recursively('error')\n      else\n        op.set_status_recursively('delayed')\n      end\n      operations.delete(op)\n    end\n    operations\n  end\n\n  # gets the number of input items in the input array of each op in list\n  #\n  # @param ops [Array] Operation List is acceptable of operations\n  # @return num_items [Int] the number of input items (Hash is acceptable)\n  def get_num_items(ops)\n\n    if ops.is_a?(Hash)\n      ops = ops.keys\n    end\n\n    num_items = 0\n    ops.each do |op|\n      num_items += op.input_array(INPUT_ARRAY).length\n    end\n    num_items\n  end\n\n\n    # Goes through and stops all failed ops and moves them to error\n  # Calls method that will also pause all plans of the same type\n  #\n  # @param operations [OperationList] list of operations\n  # @param downstream_operation_type [String] the name of the operation to be delayed\n  # @return cancel_job [Boolean] true if the job should be ended now\n  def stop_qc_failed_operations(operations, downstream_operation_type)\n    # get a list of operations that did fail qc\n    failed_ops = get_qc_fails(operations)\n    failed_ops.each do |op, failed_items|\n      plan = op.plan\n      pause_ops_of_type(plan, downstream_operation_type)\n    end\n    manage_failed_ops(operations, failed_ops, interactive: false, \n      error_failed: true, delay_similar_ops: false)\n  end\nend\n"}}]}